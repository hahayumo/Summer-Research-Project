{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8822a71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import RandomState\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import scipy\n",
    "import os\n",
    "os.environ['R_HOME'] = '/Library/Frameworks/R.framework/Versions/4.1/Resources/'\n",
    "import rpy2\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
    "import datetime\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "real_data_folder = \"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Data/sp500_mixed_period/\"\n",
    "np.random.seed(12001)\n",
    "\n",
    "\n",
    "# Define the model that generates pair simulations.\n",
    "yuima = importr(\"yuima\")\n",
    "n_jumpou_NIG_sim_string = \"\"\"\n",
    "n_jumpou_NIG = function(random_seed, num_sim,\n",
    "                        mu11, mu12, mu21, mu22, \n",
    "                        sigma11, sigma12, sigma21, sigma22,\n",
    "                        j11, j12, j21, j22,\n",
    "                        alpha, beta1, beta2, delta0, mu1, mu2, \n",
    "                        lambda11, lambda12, lambda21, lambda22,\n",
    "                        xinit_vec, T0, T, length){\n",
    "  \n",
    "  set.seed(random_seed)\n",
    "  \n",
    "  drift = c(\"mu11*t-mu12*X1\", \"mu21*t-mu22*X2\")\n",
    "  diffusion = matrix(c(\"exp(sigma11)\", \"exp(sigma12)\", \"exp(sigma21)\", \"exp(sigma22)\"), 2, 2, byrow=TRUE)\n",
    "  jumpcoef = matrix(c(\"j11\", \"j12\", \"j21\", \"j22\"), 2, 2, byrow=TRUE) \n",
    "  \n",
    "  alpha = alpha\n",
    "  beta = c(beta1, beta2)\n",
    "  delta0 = delta0\n",
    "  mu = c(mu1, mu2)\n",
    "  Lambda = matrix(c(lambda11, lambda12, lambda21, lambda22), 2, 2, byrow=TRUE)\n",
    "  \n",
    "  ou_model = setModel(drift=drift, diffusion=diffusion, jump.coeff=jumpcoef, \n",
    "                      measure.type=\"code\",\n",
    "                      measure=list(df=\"rNIG(z, alpha, beta, delta0, mu, Lambda)\"), \n",
    "                      time.variable = \"t\",\n",
    "                      state.var=c(\"X1\",\"X2\"), solve.variable=c(\"X1\",\"X2\"))\n",
    "  newsamp = setSampling(Initial=T0, Terminal=T, n=length)\n",
    "  \n",
    "  n_sim_data = data.frame(matrix(nrow=length+1, ncol=2*num_sim))\n",
    "  for (i in 1:num_sim){\n",
    "    jumpou_sim = simulate(ou_model, \n",
    "                          true.par=list(\n",
    "                            mu11=mu11, mu12=mu12, mu21=mu21, mu22=mu22, \n",
    "                            sigma11=sigma11, sigma12=sigma12, sigma21=sigma21, sigma22=sigma22,\n",
    "                            j11=j11, j12=j12, j21=j21, j22=j22,\n",
    "                            alpha=alpha, beta=beta, delta0=delta0, mu=mu, Lambda=Lambda), \n",
    "                          xinit=xinit_vec[[i]], sampling=newsamp)\n",
    "    original_data = jumpou_sim@data@original.data\n",
    "    one_sim_jumpou = data.frame(original_data[,1], original_data[,2])\n",
    "    colnames(one_sim_jumpou) = c('series1', 'series2')\n",
    "    n_sim_data[, (2*i-1):(2*i)] = one_sim_jumpou\n",
    "  }\n",
    "  return(n_sim_data)\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "n_jumpou_NIG_sim = SignatureTranslatedAnonymousPackage(n_jumpou_NIG_sim_string, \"n_jumpou_NIG_sim\")\n",
    "def n_jumpou_simulation(random_seed, num_sim,\n",
    "                        mu11, mu12, mu21, mu22, \n",
    "                        sigma11, sigma12, sigma21, sigma22,\n",
    "                        j11, j12, j21, j22,\n",
    "                        alpha, beta1, beta2, delta0, mu1, mu2, \n",
    "                        lambda11, lambda12, lambda21, lambda22,\n",
    "                        xinit_vec, T0, T, length):\n",
    "\n",
    "    n_sim_data = pd.DataFrame(\n",
    "        n_jumpou_NIG_sim.n_jumpou_NIG(random_seed, num_sim,\n",
    "                                      mu11, mu12, mu21, mu22, \n",
    "                                      sigma11, sigma12, sigma21, sigma22,\n",
    "                                      j11, j12, j21, j22,\n",
    "                                      alpha, beta1, beta2, delta0, mu1, mu2, \n",
    "                                      lambda11, lambda12, lambda21, lambda22,\n",
    "                                      xinit_vec, T0, T, length)).transpose()\n",
    "    return n_sim_data\n",
    "\n",
    "\n",
    "def price_to_log_price(n_price):\n",
    "    return(np.log(n_price))\n",
    "\n",
    "def log_price_to_price(n_log_price):\n",
    "    return(np.exp(n_log_price))\n",
    "\n",
    "def price_to_return(n_price):\n",
    "    n_return = pd.DataFrame()\n",
    "    for i in range(n_price.shape[1]):\n",
    "        ith_column_price_series = n_price.iloc[:, i]\n",
    "        n_return = pd.concat([n_return, 100 * (np.log(ith_column_price_series[1:].values) - np.log(ith_column_price_series[:-1]))], axis=1)\n",
    "    return n_return\n",
    "\n",
    "def log_price_to_return(n_log_price):\n",
    "    n_real_return = pd.DataFrame()\n",
    "    for i in range(n_log_price.shape[1]):\n",
    "        ith_column_price_series = n_log_price.iloc[:, i]\n",
    "        n_real_return = pd.concat([n_real_return, 100 * (ith_column_price_series[1:].values - ith_column_price_series[:-1])], axis=1)\n",
    "    return n_real_return\n",
    "\n",
    "\n",
    "def cross_corr_coef(lag_time_series, lead_time_series, lag):\n",
    "    # calculate the cross correlation between two time series\n",
    "    # if the result is not zero, then 'lead_time_series' leads 'lag_time_series'\n",
    "    lag_time_series = lag_time_series.iloc[lag:]\n",
    "    corr_coef = np.corrcoef(lag_time_series, lead_time_series.iloc[0:((lead_time_series.size)-lag)])[0][1]\n",
    "    return corr_coef\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cal_stats(n_return, n_price):\n",
    "    \n",
    "    return_series1 = n_return.iloc[:, ::2]\n",
    "    return_series2 = n_return.iloc[:, 1::2]\n",
    "    \n",
    "    \n",
    "    mean1 = return_series1.mean(axis=0).values\n",
    "    sd1 = return_series1.std(axis=0).values\n",
    "    skew1 = return_series1.skew(axis=0).values\n",
    "    kurtosis1 = return_series1.kurtosis(axis=0).values\n",
    "       \n",
    "    \n",
    "    mean2 = return_series2.mean(axis=0).values\n",
    "    sd2 = return_series2.std(axis=0).values\n",
    "    skew2 = return_series2.skew(axis=0).values\n",
    "    kurtosis2 = return_series2.kurtosis(axis=0).values #8(8)\n",
    "    \n",
    "    \n",
    "    stats_data = pd.DataFrame([mean1, mean2, sd1, sd2, \n",
    "                               skew1, skew2, kurtosis1, kurtosis2])#7(34)\n",
    "    stats_data = stats_data.transpose()\n",
    "    stats_data.columns = [\n",
    "        'return_mean1', 'return_mean2',\n",
    "        'return_sd1', 'return_sd2',\n",
    "        'return_skew1', 'return_skew2',\n",
    "        'return_kurtosis1', 'return_kurtosis2']\n",
    "    \n",
    "    return stats_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(params):\n",
    "\n",
    "    params = FloatVector(params)\n",
    "    print(params)\n",
    "    moment_loss = pd.DataFrame().reindex_like(real_stats)\n",
    "    \n",
    "    n_sim_log_price = n_jumpou_simulation(\n",
    "        random_seed=int(np.random.randint(low=0, high=980608, size=(1,))), num_sim=num_sim,\n",
    "        mu11=mu11, mu12=params[0], \n",
    "        mu21=mu21, mu22=params[1], \n",
    "        sigma11=params[2], sigma12=params[3], \n",
    "        sigma21=params[4], sigma22=params[5],\n",
    "        j11=params[6], j12=params[7], \n",
    "        j21=params[8], j22=params[9],\n",
    "        alpha=params[10], \n",
    "        beta1=beta1, beta2=beta2, \n",
    "        delta0=params[11], \n",
    "        mu1=params[12], mu2=params[13], \n",
    "        lambda11=params[14], lambda12=lambda12, \n",
    "        lambda21=lambda21, lambda22=1/params[14],\n",
    "        xinit_vec=xinit_vec, T0=T0, T=T, length=length)\n",
    "    \n",
    "    n_sim_price = log_price_to_price(n_sim_log_price)\n",
    "    n_sim_return = price_to_return(n_sim_price)\n",
    "    n_sim_stats = cal_stats(n_sim_return, n_sim_price)\n",
    "\n",
    "    moment_loss = np.abs(n_real_stats - n_sim_stats)\n",
    "    sum_loss = np.sum(moment_loss)\n",
    "    \n",
    "    sum_loss[0] = sum_loss[0]*50\n",
    "    sum_loss[1] = sum_loss[1]*50    \n",
    "    sum_loss[2] = sum_loss[2]*50\n",
    "    sum_loss[3] = sum_loss[3]*50\n",
    "    sum_loss[4] = sum_loss[4]*10\n",
    "    sum_loss[5] = sum_loss[5]*10\n",
    "    \n",
    "    loss = np.sum(sum_loss)\n",
    "\n",
    "    print(sum_loss)\n",
    "    print(loss)\n",
    "    print('----------')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "\n",
    "real_price = pd.read_csv(real_data_folder + \"pair_price_mixed_period_calibration.csv\", index_col=[0])\n",
    "real_log_price = price_to_log_price(n_price=real_price)\n",
    "real_return = pd.read_csv(real_data_folder + \"pair_return_mixed_period_calibration.csv\", index_col=[0])\n",
    "real_stats = cal_stats(n_return=real_return, n_price=real_price)\n",
    "\n",
    "xinit_vec = []\n",
    "for i in range(int(real_log_price.shape[1]/2)):\n",
    "    init_pair_log_price = [real_log_price.iloc[0, 2*i], real_log_price.iloc[0, 2*i+1]]\n",
    "    init_pair_log_price = FloatVector(init_pair_log_price)\n",
    "    xinit_vec.append(init_pair_log_price)\n",
    "    \n",
    "num_sim, T0, T, length = real_stats.shape[0], 0, 1, real_price.shape[0]\n",
    "n_real_stats = real_stats\n",
    "\n",
    "\n",
    "mu11 = 0\n",
    "mu21 = 0\n",
    "#alpha\n",
    "beta1 = 0\n",
    "beta2 = 0\n",
    "#delta0\n",
    "#mu1\n",
    "#mu2\n",
    "#lambda11 = 1\n",
    "lambda12 = 0\n",
    "lambda21 = 0\n",
    "#lambda22 = 1\n",
    "\n",
    "\n",
    "initial0 = [1, 1,\n",
    "            -1, -1, -1, -1,\n",
    "            0.1, 0.1, 0.1, 0.1,\n",
    "            1, 1,\n",
    "            1, 1,\n",
    "            1]\n",
    "\n",
    "begin_time = datetime.datetime.now()\n",
    "res = minimize(loss_function, initial0, method='Powell',\n",
    "               tol=1e-6, options={'disp': True},\n",
    "               bounds=[(None, None), (None, None),\n",
    "                       (None, None), (None, None), (None, None), (None, None),\n",
    "                       (None, None), (None, None), (None, None), (None, None),\n",
    "                       (0, None), (0, None),\n",
    "                       (None, None), (None, None), \n",
    "                       (0, None)])\n",
    "print(res.x)\n",
    "\n",
    "time = datetime.datetime.now() - begin_time\n",
    "print(time)\n",
    "\n",
    "params = (res.x)\n",
    "loss = loss_function((params))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc06b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_price = pd.read_csv(real_data_folder + \"pair_price_mixed_period_classification.csv\", index_col=[0])\n",
    "real_log_price = price_to_log_price(n_price=real_price)\n",
    "real_return = pd.read_csv(real_data_folder + \"pair_return_mixed_period_classification.csv\", index_col=[0])\n",
    "real_stats = cal_stats(n_return=real_return, n_price=real_price)\n",
    "\n",
    "xinit_vec = []\n",
    "for i in range(int(real_log_price.shape[1]/2)):\n",
    "    init_pair_log_price = [real_log_price.iloc[0, 2*i], real_log_price.iloc[0, 2*i+1]]\n",
    "    init_pair_log_price = FloatVector(init_pair_log_price)\n",
    "    xinit_vec.append(init_pair_log_price)\n",
    "    \n",
    "num_sim, T0, T, length = real_stats.shape[0], 0, 1, real_price.shape[0]\n",
    "\n",
    "params = FloatVector(res.x)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28106541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from numpy.random import RandomState\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "import pickle\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from supervised.automl import AutoML\n",
    "from sklearn.metrics import accuracy_score\n",
    "from supervised.preprocessing.eda import EDA\n",
    "\n",
    "def cross_corr_coef(lag_time_series, lead_time_series, lag):\n",
    "    # calculate the cross correlation between two time series\n",
    "    # if the result is not zero, then 'lead_time_series' leads 'lag_time_series'\n",
    "\n",
    "    lag_time_series = lag_time_series.iloc[lag:]\n",
    "    corr_coef = np.corrcoef(lag_time_series, lead_time_series.iloc[0:((lead_time_series.size)-lag)])[0][1]\n",
    "\n",
    "    return corr_coef\n",
    "\n",
    "def create_statistics(label, rolling_window, return_csv_location, price_csv_location):\n",
    "\n",
    "    return_df = pd.read_csv(return_csv_location, index_col=[0])\n",
    "    return_df_series1 = return_df.iloc[:, ::2]\n",
    "    return_df_series2 = return_df.iloc[:, 1::2]\n",
    "    \n",
    "    price_df = pd.read_csv(price_csv_location, index_col=[0])\n",
    "    price_df_series1 = price_df.iloc[:, ::2]\n",
    "    price_df_series2 = price_df.iloc[:, 1::2]\n",
    "\n",
    "    \n",
    "    return_mean1 = return_df_series1.mean(axis=0).values\n",
    "    sd1 = return_df_series1.std(axis=0).values\n",
    "    skew1 = return_df_series1.skew(axis=0).values\n",
    "    kurtosis1 = return_df_series1.kurtosis(axis=0).values\n",
    "    \n",
    "    autocorrelation_return1_lag1 = return_df_series1.apply(lambda x: x.autocorr(lag=1))\n",
    "    autocorrelation_return1_lag2 = return_df_series1.apply(lambda x: x.autocorr(lag=2))\n",
    "    autocorrelation_return1_lag3 = return_df_series1.apply(lambda x: x.autocorr(lag=3))    \n",
    "    #rolling_window = rolling_window\n",
    "    #rolling_return_sd1 = return_df_series1.apply(lambda x: x.rolling(rolling_window).std()).iloc[rolling_window + 1:]\n",
    "    #autocorrelation_return_rolling_sd1 = rolling_return_sd1.apply(lambda x: x.autocorr(lag=1))\n",
    "\n",
    "    \n",
    "    return_mean2 = return_df_series2.mean(axis=0).values\n",
    "    sd2 = return_df_series2.std(axis=0).values\n",
    "    skew2 = return_df_series2.skew(axis=0).values\n",
    "    kurtosis2 = return_df_series2.kurtosis(axis=0).values\n",
    "    \n",
    "    autocorrelation_return2_lag1 = return_df_series2.apply(lambda x: x.autocorr(lag=1))\n",
    "    autocorrelation_return2_lag2 = return_df_series2.apply(lambda x: x.autocorr(lag=2))\n",
    "    autocorrelation_return2_lag3 = return_df_series2.apply(lambda x: x.autocorr(lag=3))\n",
    "    #rolling_return_sd2 = return_df_series2.apply(lambda x: x.rolling(rolling_window).std()).iloc[rolling_window + 1:]\n",
    "    #autocorrelation_return_rolling_sd2 = rolling_return_sd2.apply(lambda x: x.autocorr(lag=1))\n",
    "\n",
    "\n",
    "    # Cross-correlation between return series\n",
    "    corr_ts1_lag_0 = []\n",
    "    corr_ts1_lag_1 = [] # if not zero, return series 2 leads return series 1\n",
    "    corr_ts1_lag_2 = []\n",
    "    corr_ts1_lag_3 = []\n",
    "    corr_ts2_lag_1 = [] # if not zero, return series 1 lead return series 2\n",
    "    corr_ts2_lag_2 = []\n",
    "    corr_ts2_lag_3 = []\n",
    "    for i in range(248):\n",
    "        corr_ts1_lag_0.append(cross_corr_coef(return_df_series1.iloc[:, i], return_df_series2.iloc[:, i], 0))\n",
    "        corr_ts1_lag_1.append(cross_corr_coef(return_df_series1.iloc[:, i], return_df_series2.iloc[:, i], 1))\n",
    "        corr_ts1_lag_2.append(cross_corr_coef(return_df_series1.iloc[:, i], return_df_series2.iloc[:, i], 2))\n",
    "        corr_ts1_lag_3.append(cross_corr_coef(return_df_series1.iloc[:, i], return_df_series2.iloc[:, i], 3))\n",
    "        corr_ts2_lag_1.append(cross_corr_coef(return_df_series2.iloc[:, i], return_df_series1.iloc[:, i], 1))\n",
    "        corr_ts2_lag_2.append(cross_corr_coef(return_df_series2.iloc[:, i], return_df_series1.iloc[:, i], 2))\n",
    "        corr_ts2_lag_3.append(cross_corr_coef(return_df_series2.iloc[:, i], return_df_series1.iloc[:, i], 3))\n",
    "    corr_ts1_lag_0 = pd.Series(corr_ts1_lag_0)\n",
    "    corr_ts1_lag_1 = pd.Series(corr_ts1_lag_1)\n",
    "    corr_ts1_lag_2 = pd.Series(corr_ts1_lag_2)\n",
    "    corr_ts1_lag_3 = pd.Series(corr_ts1_lag_3)\n",
    "    corr_ts2_lag_1 = pd.Series(corr_ts2_lag_1)\n",
    "    corr_ts2_lag_2 = pd.Series(corr_ts2_lag_2)\n",
    "    corr_ts2_lag_3 = pd.Series(corr_ts2_lag_3)#21\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    sq_return_series1 = return_df_series1**2\n",
    "    sq_return_series2 = return_df_series2**2\n",
    "    #Â Autocorrelation of the 2 squared returns with 3 lags respectively\n",
    "    autocorr_sqreturn_1_lag_1 = sq_return_series1.apply(lambda x: x.autocorr(lag=1))\n",
    "    autocorr_sqreturn_1_lag_2 = sq_return_series1.apply(lambda x: x.autocorr(lag=2))\n",
    "    autocorr_sqreturn_1_lag_3 = sq_return_series1.apply(lambda x: x.autocorr(lag=3))\n",
    "    autocorr_sqreturn_2_lag_1 = sq_return_series2.apply(lambda x: x.autocorr(lag=1)) \n",
    "    autocorr_sqreturn_2_lag_2 = sq_return_series2.apply(lambda x: x.autocorr(lag=2)) \n",
    "    autocorr_sqreturn_2_lag_3 = sq_return_series2.apply(lambda x: x.autocorr(lag=3))#27\n",
    "    \n",
    "    # Cross-correlation between squared returns series\n",
    "    corr_sqts1_lag_0 = []\n",
    "    corr_sqts1_lag_1 = [] # if not zero, return series 2 leads return series 1\n",
    "    corr_sqts1_lag_2 = []\n",
    "    corr_sqts1_lag_3 = []\n",
    "    corr_sqts2_lag_1 = [] # if not zero, return series 1 lead return series 2\n",
    "    corr_sqts2_lag_2 = []\n",
    "    corr_sqts2_lag_3 = []\n",
    "    for i in range(int(real_price.shape[1]/2)):\n",
    "        corr_sqts1_lag_0.append(cross_corr_coef(sq_return_series1.iloc[:, i], sq_return_series2.iloc[:, i], 0))\n",
    "        corr_sqts1_lag_1.append(cross_corr_coef(sq_return_series1.iloc[:, i], sq_return_series2.iloc[:, i], 1))\n",
    "        corr_sqts1_lag_2.append(cross_corr_coef(sq_return_series1.iloc[:, i], sq_return_series2.iloc[:, i], 2))\n",
    "        corr_sqts1_lag_3.append(cross_corr_coef(sq_return_series1.iloc[:, i], sq_return_series2.iloc[:, i], 3))\n",
    "        corr_sqts2_lag_1.append(cross_corr_coef(sq_return_series2.iloc[:, i], sq_return_series1.iloc[:, i], 1))\n",
    "        corr_sqts2_lag_2.append(cross_corr_coef(sq_return_series2.iloc[:, i], sq_return_series1.iloc[:, i], 2))\n",
    "        corr_sqts2_lag_3.append(cross_corr_coef(sq_return_series2.iloc[:, i], sq_return_series1.iloc[:, i], 3))\n",
    "    corr_sqts1_lag_0 = pd.Series(corr_ts1_lag_0)\n",
    "    corr_sqts1_lag_1 = pd.Series(corr_ts1_lag_1)\n",
    "    corr_sqts1_lag_2 = pd.Series(corr_ts1_lag_2)\n",
    "    corr_sqts1_lag_3 = pd.Series(corr_ts1_lag_3)\n",
    "    corr_sqts2_lag_1 = pd.Series(corr_ts2_lag_1)\n",
    "    corr_sqts2_lag_2 = pd.Series(corr_ts2_lag_2)\n",
    "    corr_sqts2_lag_3 = pd.Series(corr_ts2_lag_3)#7(34)\n",
    "    \n",
    "    \n",
    "    ### Granger Causality test\n",
    "    price2_granger_cause_price1 = []\n",
    "    price1_granger_cause_price2 = []\n",
    "    for i in range(248):\n",
    "        ts1 = price_df_series1.iloc[:, i]\n",
    "        ts2 = price_df_series2.iloc[:, i]\n",
    "        bivariate_time_series = np.array(pd.DataFrame([ts1, ts2]).transpose())\n",
    "        var_model = VAR(bivariate_time_series)\n",
    "        var_result_aic = []\n",
    "\n",
    "        for j in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "            var_model_fit = var_model.fit(j)\n",
    "            var_result_aic.append(var_model_fit.aic)\n",
    "\n",
    "        var_lag = np.where(var_result_aic == np.min(var_result_aic))[0][0] + 1\n",
    "        our_var_model = VAR(bivariate_time_series)\n",
    "        our_var_model_fitted = our_var_model.fit(var_lag)\n",
    "\n",
    "        # granger causality test, output p-value of the F-test\n",
    "        # For price2_granger_cause_price1, if p-value is less than 0.05, ts2 granger causes ts1, that is, the past values of ts2 have a statistically significant effect on the current value of ts1\n",
    "        bivariate_ts1_ts2 = np.array(pd.DataFrame([ts1, ts2]).transpose())\n",
    "        bivariate_ts2_ts1 = np.array(pd.DataFrame([ts2, ts1]).transpose())\n",
    "        price2_granger_cause_price1.append(grangercausalitytests(bivariate_ts1_ts2, [var_lag])[var_lag][0][\"ssr_ftest\"][1])\n",
    "        price1_granger_cause_price2.append(grangercausalitytests(bivariate_ts2_ts1, [var_lag])[var_lag][0][\"ssr_ftest\"][1])\n",
    "\n",
    "    price2_granger_cause_price1 = pd.Series(price2_granger_cause_price1)\n",
    "    price1_granger_cause_price2 = pd.Series(price1_granger_cause_price2)#36\n",
    "\n",
    "\n",
    "    ### create new statistics data frame\n",
    "    new_statistics = pd.DataFrame([\n",
    "        return_mean1, return_mean2,\n",
    "        sd1, sd2,\n",
    "        skew1, skew2,\n",
    "        kurtosis1, kurtosis2, #8\n",
    "        \n",
    "        autocorrelation_return1_lag1, autocorrelation_return1_lag2, autocorrelation_return1_lag3,\n",
    "        autocorrelation_return2_lag1, autocorrelation_return2_lag2, autocorrelation_return2_lag3, #6(14)\n",
    "\n",
    "        #autocorrelation_return_rolling_sd1, autocorrelation_return_rolling_sd2,\n",
    "        corr_ts1_lag_0,\n",
    "        corr_ts1_lag_1, corr_ts1_lag_2, corr_ts1_lag_3,\n",
    "        corr_ts2_lag_1, corr_ts2_lag_2, corr_ts2_lag_3, #7(21)\n",
    "        \n",
    "        autocorr_sqreturn_1_lag_1, autocorr_sqreturn_1_lag_2, autocorr_sqreturn_1_lag_3,\n",
    "        autocorr_sqreturn_2_lag_1, autocorr_sqreturn_2_lag_2, autocorr_sqreturn_2_lag_3,#6(27)    \n",
    "\n",
    "        corr_sqts1_lag_0,\n",
    "        corr_sqts1_lag_1, corr_sqts1_lag_2, corr_sqts1_lag_3,\n",
    "        corr_sqts2_lag_1, corr_sqts2_lag_2, corr_sqts2_lag_3,#34\n",
    "\n",
    "        price2_granger_cause_price1, price1_granger_cause_price2 #2 (36)\n",
    "        ])\n",
    "    \n",
    "    new_statistics = new_statistics.transpose()\n",
    "    new_statistics.columns = [\n",
    "        'return_mean1', 'return_mean2',\n",
    "        'return_sd1', 'return_sd2',\n",
    "        'return_skew1', 'return_skew2',\n",
    "        'return_kurtosis1', 'return_kurtosis2',\n",
    "        \n",
    "        'return_autocorrelation_1_lag1', 'return_autocorrelation_1_lag2', 'return_autocorrelation_1_lag3',\n",
    "        'return_autocorrelation_2_lag1', 'return_autocorrelation_2_lag2', 'return_autocorrelation_2_lag3',\n",
    "        \n",
    "        #'return_autocorrelation_lag1_rolling_sd1', 'return_autocorrelation_lag1_rolling_sd2',\n",
    "        'return_correlation_ts1_lag_0',\n",
    "        'return_correlation_ts1_lag_1', 'return_correlation_ts1_lag_2', 'return_correlation_ts1_lag_3',\n",
    "        'return_correlation_ts2_lag_1', 'return_correlation_ts2_lag_2', 'return_correlation_ts2_lag_3',\n",
    "    \n",
    "        'sqreturn_autocorrelation_ts1_lag1', 'sqreturn_autocorrelation_ts1_lag2', 'sqreturn_autocorrelation_ts1_lag3',\n",
    "        'sqreturn_autocorrelation_ts2_lag1', 'sqreturn_autocorrelation_ts2_lag2', 'sqreturn_autocorrelation_ts2_lag3',\n",
    "    \n",
    "        'sqreturn_correlation_ts1_lag_0',\n",
    "        'sqreturn_correlation_ts1_lag_1', 'sqreturn_correlation_ts1_lag_2', 'sqreturn_correlation_ts1_lag_3', \n",
    "        'sqreturn_correlation_ts2_lag_1', 'sqreturn_correlation_ts2_lag_2', 'sqreturn_correlation_ts2_lag_3',\n",
    "        \n",
    "        'price2_granger_cause_price1', 'price1_granger_cause_price2']#36\n",
    "    \n",
    "    label_col_position = new_statistics.shape[1]\n",
    "    new_statistics.insert(label_col_position, 'label', label, allow_duplicates=True)\n",
    "\n",
    "    return new_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5b16b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(9868)\n",
    "num_iter = 5\n",
    "random_seeds = np.random.randint(low=0, high=980608, size=(num_iter,))\n",
    "results = []\n",
    "\n",
    "\n",
    "real_statistics = create_statistics(\n",
    "    label=\"real\", \n",
    "    rolling_window=20, \n",
    "    return_csv_location=real_data_folder + \"pair_return_mixed_period_classification.csv\", \n",
    "    price_csv_location=real_data_folder + \"pair_price_mixed_period_classification.csv\")\n",
    "    \n",
    "    \n",
    "for iter in range(num_iter):\n",
    "\n",
    "    random_seed = int(random_seeds[iter])\n",
    "    \n",
    "    n_sim_jumpou_log_prices = n_jumpou_simulation(\n",
    "        random_seed=random_seed, num_sim=248,\n",
    "        mu11=mu11, mu12=params[0], \n",
    "        mu21=mu21, mu22=params[1], \n",
    "        sigma11=params[2], sigma12=params[3], \n",
    "        sigma21=params[4], sigma22=params[5],\n",
    "        j11=params[6], j12=params[7], \n",
    "        j21=params[8], j22=params[9],\n",
    "        alpha=params[10], \n",
    "        beta1=beta1, beta2=beta2, \n",
    "        delta0=params[11], \n",
    "        mu1=params[12], mu2=params[13], \n",
    "        lambda11=params[14], lambda12=lambda12, \n",
    "        lambda21=lambda21, lambda22=1/params[14],\n",
    "        xinit_vec=xinit_vec, T0=T0, T=T, length=length)\n",
    "    \n",
    "\n",
    "    n_sim_jumpou_pair_prices = log_price_to_price(n_log_price=n_sim_jumpou_log_prices)\n",
    "    n_sim_jumpou_pair_returns = price_to_return(n_price=n_sim_jumpou_pair_prices)\n",
    "\n",
    "    n_sim_jumpou_pair_prices.to_csv(\"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Calibration/Cluster jobs/ou_jump_stvol/n_sim_jumpou_pair_prices.csv\")\n",
    "    n_sim_jumpou_pair_returns.to_csv(\"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Calibration/Cluster jobs/ou_jump_stvol/n_sim_jumpou_pair_returns.csv\")\n",
    "    \n",
    "    \n",
    "    simulated_statistics = create_statistics(\n",
    "        label=\"simulated\", \n",
    "        rolling_window=20, \n",
    "        return_csv_location=\"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Calibration/Cluster jobs/ou_jump_stvol/n_sim_jumpou_pair_returns.csv\", \n",
    "        price_csv_location=\"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Calibration/Cluster jobs/ou_jump_stvol/n_sim_jumpou_pair_prices.csv\")\n",
    "\n",
    "\n",
    "    dataset = pd.concat([real_statistics, simulated_statistics])\n",
    "    X = dataset.iloc[:, 0:36]\n",
    "    y = dataset.iloc[:, 36]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random_seed)\n",
    "    automl = AutoML(eval_metric='accuracy')\n",
    "    automl.fit(X_train, y_train)\n",
    "    predictions = automl.predict(X_test)\n",
    "    accuracy_result = accuracy_score(y_test, predictions)\n",
    "    results.append(accuracy_result)\n",
    "    \n",
    "    print(f\"Accuracy of predictions:  {accuracy_result:.3f}\")\n",
    "\n",
    "accuracy_average = np.mean(results)\n",
    "accuracy_std = np.std(results)\n",
    "EDA.extensive_eda(X_train, y_train, save_path=\"/Users/changmao/Desktop/OneDrive - Imperial College London/InferStat - MSc Summer Project/GitHub/Summer-Research-Project/Calibration/Cluster jobs/ou_jump_stvol/EDA_oujump\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee15261",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)\n",
    "print(accuracy_average)\n",
    "print(accuracy_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
